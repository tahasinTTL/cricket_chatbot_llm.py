{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ipython\n",
    "%pip install --upgrade langchain -q\n",
    "\n",
    "# requires for openai embedding\n",
    "# %pip install tiktoken -q\n",
    "# %pip install huggingface_hub\n",
    "%pip install faiss-cpu\n",
    "%pip install InstructorEmbedding\n",
    "# %pip install sentence-transformers==2.2.2\n",
    "# %pip install pypdf2\n",
    "# %pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample flowchart of the Task. From this flowchart, I skip the pinecone part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "open_image = Image.open('flowchart.png')\n",
    "display(open_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the Doc file into PDF for my good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# loader = Docx2txtLoader('/content/drive/MyDrive/cricket_test/Cricket.docx')\n",
    "# documents = loader.load()\n",
    "\n",
    "def get_pdf_text(pdf_docs):\n",
    "  text = \"\"\n",
    "  pdf_reader = PdfReader(pdf_docs)\n",
    "  for page in pdf_reader.pages:\n",
    "    text += page.extract_text()\n",
    "    \n",
    "  return text\n",
    "\n",
    "text = get_pdf_text('Cricket.pdf')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I splitted the pdf into chunk file for easily upload to the model to avoid any interruption during the embed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "def split_docs(text):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, length_function=len)\n",
    "  docs = text_splitter.split_text(text)\n",
    "  return docs\n",
    "\n",
    "docs = split_docs(text)\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Huggingface I've using 'Instructor-XL' model for embedding the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "def get_vectoriser(text_chunk):\n",
    "  embeddings = HuggingFaceInstructEmbeddings(model_name='hkunlp/instructor-xl')\n",
    "  vectoriser = FAISS.from_texts(texts=text_chunk, embedding=embeddings)\n",
    "  return vectoriser\n",
    "\n",
    "query_result = get_vectoriser(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i've using the Cohere model for creating the chatbot and feeding the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_community cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatCohere\n",
    "\n",
    "# OPENAI_API_KEY = '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'\n",
    "cohere_api_key = 'E42pCnMqJGjdlpEpxMsUROSl7YmfKwPBXGAAbo1A'\n",
    "def get_conversation(vectoriser):\n",
    "  llm = ChatCohere(cohere_api_key=cohere_api_key, model='command', max_tokens=256, temperature=0.75)\n",
    "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "  conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=vectoriser.as_retriever(), memory=memory)\n",
    "  return conversation_chain\n",
    "\n",
    "conversation = get_conversation(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I've asked the bot those 3 questions that gave me in the task file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_input(question):\n",
    "    response = conversation(question)\n",
    "    return response\n",
    "\n",
    "answer = handle_input('How should you position your hands and adjust your head when catching a flat trajectory ball aimed at head height?')\n",
    "question = answer['question']\n",
    "ans = answer['chat_history'][1]\n",
    "print('question: ', question)\n",
    "print('answer ', ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = handle_input('What are some general points for fielders to keep in mind during a cricket match?')\n",
    "question = answer['question']\n",
    "ans = answer['chat_history'][1]\n",
    "print('question: ', question)\n",
    "print('answer: ', ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = handle_input('When were the modern Laws of cricket first written down and printed?')\n",
    "question = answer['question']\n",
    "ans = answer['chat_history'][1]\n",
    "print('question: ', question)\n",
    "print('answer: ', ans)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
